
선형 대수는 과학과 공학 분야에서 널리 쓰이는 수학의 가지이다. 그러나 많은 컴퓨터 학자들은 연속 수학보다는 이산 수학을 배우기 때문에 이와 관련한 경험이 적다. 선형 대수에 대한 올바른 이해는 많은 머신러닝 알고리즘을 이해하는데 도움을 주며, 특히 딥러닝 알고리즘의 핵심이다. 그러므로 우리는 딥러닝과 함께 선형 대수의 핵심적인 표현에 초점을 맞춰 설명할 것이다.


# 2.1 스칼라, 벡터, 행렬 그리고 텐서

- 스칼라: 그냥 숫자이다. 방향이 없다.
- 벡터: 숫자들의 순서가 있는 나열이다. 벡터 안에 있는 각 숫자들을 원소(element) 라 부르며, 벡터 $\textbf{x}$ 의 $i$ 번째 원소는 $\textbf{x}_{i}$ 라고 표기한다. n개의 원소를 가지는 벡터를 n차원 벡터라고 부르며, $\textbf{x} \in R^{n}$ 로 표기한다. 벡터는 기하적으로 n차원 공간 상의 점에 대응 된다.
- 


# 2.2 행렬곱과 벡터

행렬의 곱은 스칼라의 곱과는 다르게 정의된다. 이러한 정의 때문에 분배법칙과 결합법칙은 성립하나, 교환법칙이 성립하지 않는다.
즉, 보통 $AB = BA$ 는 성립하지 않는다.